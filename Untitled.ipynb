{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Finding Lane Lines on the Road** \n",
    "[![Udacity - Self-Driving Car NanoDegree](https://s3.amazonaws.com/udacity-sdc/github/shield-carnd.svg)](http://www.udacity.com/drive)\n",
    "\n",
    "<img src=\"writeup_images/7.png\" width=\"480\" alt=\"Combined Image\" />\n",
    "\n",
    "Overview\n",
    "---\n",
    "\n",
    "\n",
    "The aim of this project is to detect lane lines in a video, based on the knowledge gained through Udacity's teachings in the first week. The project is written in Python, and was tested in the Jupyter Notebook on the given input videos and images. The input videos were annotated by the red lane markings computed over the original content of the video.\n",
    "\n",
    "\n",
    "[//]: # (Image References)\n",
    "\n",
    "[image1]: ./writeup_images/1.png \"Original\"\n",
    "[image2]: ./writeup_images/2.png \"Grayscale\"\n",
    "[image3]: ./writeup_images/3.png \"Blurred\"\n",
    "[image4]: ./writeup_images/4.png \"Canny\"\n",
    "[image5]: ./writeup_images/5.png \"Masked\"\n",
    "[image6]: ./writeup_images/6.png \"Hough Lines\"\n",
    "[image7]: ./writeup_images/7.png \"Final\"\n",
    "---\n",
    "\n",
    "## Reflection\n",
    "\n",
    "### Pipline Implementation\n",
    "\n",
    "\n",
    "\n",
    "![alt text][image1]\n",
    "\n",
    "The pipeline consists of 8 steps and is implemented in lane_line_detector().\n",
    "\n",
    "1. The input image is converted to grayscale\n",
    "\n",
    "  ![alt text][image2]\n",
    "\n",
    "2. The Guassian Blur is applied to smooth the image and slightly remove noises. The kernel size was set to 5.\n",
    "\n",
    "  ![alt text][image3]\n",
    "\n",
    "3. Canny edge detection is used.\n",
    "\n",
    "  ![alt text][image4]\n",
    "\n",
    "4. A four sided polygon is created to mask the the image with detected edges \n",
    "\n",
    "  ![alt text][image5]\n",
    "\n",
    "5. Lines in the image are extracted using the Hough transform with the following parameters:\n",
    "    | Parameter | Value | Description\n",
    "    | :-- | :--- | :---\n",
    "    | rho | 2 | Distance resolution in pixels of the Hough grid\n",
    "    | theta | Pi/180 | Angular resolution in radians of the Hough grid\n",
    "    | threshold | 40 | Minimum number of votes (intersections in Hough grid cell)\n",
    "    | min_line_length | 40 | Minimum number of pixels making up a line\n",
    "    | max_line_gap | 150 | Maximum gap in pixels between connectable line segments\n",
    "\n",
    "6. Lines are classified into left and right lines. In order to that, the minimum and maximum slopes of the lines in the image are obtained. Then those lines that fall within 70% of the minimum and maximum slopes are classified as the left and right lines.\n",
    "\n",
    "7. The left and right side lines are extrapolated by averaging their slope and intercept respectively. This is done by changing the draw_lines() method. The result of steps 5, 6 and 7 is depicted in the following figure:\n",
    "\n",
    " ![alt text][image6]\n",
    "\n",
    "8. The lines are overlayed on the input image to mark the lane.\n",
    "\n",
    " ![alt text][image7]\n",
    "\n",
    "\n",
    "\n",
    "### Potential Shortcomings \n",
    "\n",
    "Lane lines are not always clearly marked or visible. Different lighting conditions and artifacts on the road might partially cover the lane markings. Additionally, in many situations where the road is under construction, the lanes are not properly and clearly marked. It might be necessary to distinguish between the yellow and white lane markings the detect the correct lane.\n",
    "\n",
    "Another problem might appear when there are shadows or white lines in the image. This will cause the classification algorithm to not function properly. Therefore a better classification method is needed.\n",
    "\n",
    "\n",
    "### Possible Improvements\n",
    "\n",
    "A possible improvement would be to apply a better noise reduction method on the image to remove unwanted artifacts in the image. Also, it would more effecient to dynamically detect the thresholds and parameters according to the image characteristics, so that the detection of lines becomes more accurate. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
